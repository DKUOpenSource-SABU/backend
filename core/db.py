import os
import pickle

import pandas as pd
from scipy.spatial import ConvexHull
import numpy as np
from pathlib import Path

from clustering.Kmeans import *


# ------- DB ì´ˆê¸°í™” ë° ë°ì´í„° ë¡œë”© ------
# ì‘ì„±ì : ê¹€íƒœí˜•
if not os.path.exists('./collect/ticker_etf.csv') or \
    not os.path.exists('./collect/ticker_stock.csv'):
    raise FileNotFoundError("í•„ìš”í•œ CSV íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. \
                            ./collect/ í´ë”ì— ticker_etf.csvì™€ \
                            ticker_stock.csv íŒŒì¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
print("DB Initialize...")

# ETF í‹°ì»¤ ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
df_etf = pd.read_csv('./collect/ticker_etf.csv', encoding='utf-8')
df_etf = df_etf.iloc[:-1]
df_etf = df_etf.drop("1 yr % CHANGE", axis=1)
df_etf['SECTOR'] = "ETF"

# ì£¼ì‹ í‹°ì»¤ ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
df_stock = pd.read_csv('./collect/ticker_stock.csv', encoding='utf-8')
df_stock = df_stock.rename(columns={'Symbol': 'SYMBOL', 
                                    'Name': 'NAME',
                                    'Last Sale': 'LAST PRICE', 
                                    '% Change': '% CHANGE',
                                    'Sector' : 'SECTOR'})
df_stock['SECTOR'] = df_stock['SECTOR'].fillna('N/A')

# ê³µí†µ ì»¬ëŸ¼ ì¶”ì¶œ ë° ë°ì´í„° ë³‘í•© (ì£¼ì‹ & ETF)
common_cols = df_etf.columns.intersection(df_stock.columns)
df = pd.concat([df_stock[common_cols],
                df_etf[common_cols]], 
                ignore_index=True).dropna()
print("DB Create Complete...")


# ------- ëª¨ë“  ì£¼ê°€ ë°ì´í„° ì‚¬ì „ íŠ¸ë ˆì´ë‹ -------
# ì‘ì„±ì : ê¹€íƒœí˜•

# ì¬ì‹œì‘ ì‹œë§ˆë‹¤ k_meansë¥¼ ìƒˆë¡œ ê³„ì‚°í•˜ì§€ ì•Šë„ë¡ ìºì‹œ ê²½ë¡œ ì„¤ì •
CACHE_PATH = Path("models/pretrained_data.pkl")

# k_meansë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ì „ íŠ¸ë ˆì´ë‹ ë°ì´í„° ìƒì„± í•¨ìˆ˜
# ì´ í•¨ìˆ˜ëŠ” ìºì‹œë¥¼ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ìµœì í™”í•©ë‹ˆë‹¤.
# ì‘ì„±ì : ê¹€íƒœí˜•
def get_pretrained_data_db(df_symbols=df['SYMBOL'][:-1].tolist(),
                            *,
                             force_refresh=False,
                             cache_path=CACHE_PATH):
    if cache_path.exists() and not force_refresh:
        with cache_path.open("rb") as f:
            print(f"ğŸ“„ ìºì‹œ ë¡œë“œ: {cache_path}")
            return pickle.load(f)
        
    print("ğŸ§® k_means ì¬ê³„ì‚° ì¤‘ â€¦")
    pretrained_data = k_means(df_symbols)
    cache_path.parent.mkdir(parents=True, exist_ok=True)

    with cache_path.open("wb") as f:
        pickle.dump(pretrained_data, f)
        print(f"ğŸ’¾ ìºì‹œ ì €ì¥ ì™„ë£Œ: {cache_path}")

    return pretrained_data

# ì‚¬ì „ íŠ¸ë ˆì´ë‹ ë°ì´í„° ë¡œë”©
print("Pretraining...")
pretrained_data = get_pretrained_data_db()
cluster_map = pretrained_data.set_index("ticker")["cluster"].to_dict()

# ê¸°ë³¸ í´ëŸ¬ìŠ¤í„° ì‹œê°í™”ë¥¼ ìœ„í•œ Convex Hull ìƒì„±
# Convex Hullì„ ì‚¬ìš©í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ë§ ì‹œê°í™”
# ì‘ì„±ì : ê¹€íƒœí˜•
hull_list = []
for cluster in pretrained_data["cluster"].unique().tolist():
    cluster_points = pretrained_data[pretrained_data["cluster"] == cluster]
    if len(cluster_points) < 3:
        continue
    points = cluster_points[["PC1", "PC2"]].values
    hull = ConvexHull(points)
    ordered = np.append(hull.vertices, hull.vertices[0])
    hull_coords = [{"x": float(points[i][0]),
                    "y": float(points[i][1])} for i in ordered]
    hull_list.append({
        "cluster": int(cluster),
        "hull_coords" : hull_coords,
        })

# ------- DB ì ‘ê·¼ Getter ------
# ëª¨ë“  í‹°ì»¤ ì •ë³´ ë° í´ëŸ¬ìŠ¤í„° ì •ë³´ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
# ì‘ì„±ì : ê¹€íƒœí˜•
def get_all_tickers():
    global df
    return {
        row["SYMBOL"]: {
            **row,
            "CLUSTER": cluster_map.get(row["SYMBOL"], None)
        }
        for row in df.to_dict(orient="records")
    }

# ëª¨ë“  í´ëŸ¬ìŠ¤í„°ì˜ Convex Hull ì¢Œí‘œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
# ì‘ì„±ì : ê¹€íƒœí˜•
def get_hull_list():
    global hull_list
    return hull_list

# ì‚¬ì „ íŠ¸ë ˆì´ë‹ ë°ì´í„°ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
# ì‘ì„±ì : ê¹€íƒœí˜•
def get_pretrained_data():
    global pretrained_data
    return pretrained_data