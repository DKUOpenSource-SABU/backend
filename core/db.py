import pandas as pd
from clustering.Kmeans import *
import os
from scipy.spatial import ConvexHull
import numpy as np
import pickle
from pathlib import Path

print("Loading data...")
df_etf = pd.read_csv('./collect/ticker_etf.csv', encoding='utf-8')
df_etf = df_etf.iloc[:-1]
df_etf = df_etf.drop("1 yr % CHANGE", axis=1)
df_etf['SECTOR'] = "ETF"

df_stock = pd.read_csv('./collect/ticker_stock.csv', encoding='utf-8')

df_stock = df_stock.rename(columns={'Symbol': 'SYMBOL', 'Name': 'NAME', 'Last Sale': 'LAST PRICE', '% Change': '% CHANGE', 'Sector' : 'SECTOR'})

common_cols = df_etf.columns.intersection(df_stock.columns)

df_stock['SECTOR'] = df_stock['SECTOR'].fillna('N/A')
df = pd.concat([df_stock[common_cols], df_etf[common_cols]], ignore_index=True).dropna()

print("DB Create Complete...")

def get_all_tickers():
    global df
    return {
        row["SYMBOL"]: {
            **row,
            "CLUSTER": cluster_map.get(row["SYMBOL"], None)  # SYMBOL â†’ ticker ë§¤í•‘
        }
        for row in df.to_dict(orient="records")
    }

def get_hull_list():
    global hull_list
    return hull_list

CACHE_PATH = Path("models/pretrained_data.pkl")   # ì›í•˜ëŠ” ìœ„ì¹˜Â·ì´ë¦„ìœ¼ë¡œ ë³€ê²½

def get_pretrained_data_db(df_symbols=df['SYMBOL'][:-1].tolist(), *, force_refresh=False, cache_path=CACHE_PATH):
    """
    df_symbols : ì‹œê³„ì—´ ë“± ì „ì²˜ë¦¬ ëë‚œ DataFrameì˜ SYMBOL ì»¬ëŸ¼ (iterable)
    force_refresh: Trueë©´ ìºì‹œ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ê³„ì‚°
    cache_path   : ìºì‹œ íŒŒì¼ ê²½ë¡œ
    """
    # 1) ìºì‹œê°€ ìˆê³  ê°•ì œ ìƒˆë¡œê³ ì¹¨ì´ ì•„ë‹ˆë©´ â†’ ë°”ë¡œ ë¡œë“œ
    if cache_path.exists() and not force_refresh:
        with cache_path.open("rb") as f:
            print(f"ğŸ“„ ìºì‹œ ë¡œë“œ: {cache_path}")
            return pickle.load(f)

    # 2) ì—†ìœ¼ë©´ k_means ì¬ê³„ì‚°
    print("ğŸ§® k_means ì¬ê³„ì‚° ì¤‘ â€¦")
    pretrained_data = k_means(df_symbols)

    # 3) ìºì‹œ ì €ì¥
    cache_path.parent.mkdir(parents=True, exist_ok=True)
    with cache_path.open("wb") as f:
        pickle.dump(pretrained_data, f)
        print(f"ğŸ’¾ ìºì‹œ ì €ì¥ ì™„ë£Œ: {cache_path}")

    return pretrained_data

def get_pretrained_data():
    global pretrained_data
    return pretrained_data


pretrained_data = get_pretrained_data_db()

print("Pretraining...")
cluster_map = pretrained_data.set_index("ticker")["cluster"].to_dict()

# PreTrain Convex Hull
hull_list = []
for cluster in pretrained_data["cluster"].unique().tolist():
    # Convex Hullì„ ì‚¬ìš©í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ë§
    cluster_points = pretrained_data[pretrained_data["cluster"] == cluster]
    if len(cluster_points) < 3:
        continue
    points = cluster_points[["PC1", "PC2"]].values
    hull = ConvexHull(points)
    ordered = np.append(hull.vertices, hull.vertices[0])
    hull_coords = [{"x": float(points[i][0]), "y": float(points[i][1])} for i in ordered]
    hull_list.append({
        "cluster": int(cluster),
        "hull_coords" : hull_coords,
        })